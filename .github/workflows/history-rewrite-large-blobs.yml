name: History Rewrite (Large Blobs Removal)

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Type YES to confirm destructive history rewrite (only for non-dry run)'
        required: false
        default: ''
      dry_run:
        description: 'true = diagnostics only; false = allow rewrite (with confirm)'
        required: false
        default: 'true'

jobs:
  rewrite:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout full history
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Capture remote URL (pre-rewrite)
        run: |
          git config --get remote.origin.url > remote_url.txt || echo '' > remote_url.txt
          echo "Captured remote URL: $(cat remote_url.txt)"

      - name: Pre size + head
        run: |
          git count-objects -vH || true
          git rev-parse HEAD > pre_rewrite_head.txt

      - name: Baseline largest blobs
        run: |
          for idx in .git/objects/pack/pack-*.idx; do
            git verify-pack -v "$idx" | awk '/ blob /{print $1, $3}';
          done | sort -k2 -n | tail -50 > baseline_largest_blobs.txt
          tail -10 baseline_largest_blobs.txt

      - name: Map largest blobs to paths
        run: |
          # Extract just the SHA column and map to paths (may list multiple paths if reused)
          awk '{print $1}' baseline_largest_blobs.txt > baseline_shas.txt
          # Use rev-list to map SHAs to paths; suppress errors for missing (should not happen here)
          git rev-list --objects --all | grep -F -f baseline_shas.txt > largest_blob_paths.txt || true
          echo "Top mapped entries:" && head -20 largest_blob_paths.txt || true

      - name: Extract target list (pre)
        run: |
          # Parse TARGET SHAs from the rewrite script to avoid drift between presence checks and actual rewrite.
          grep -oE 'b"[0-9a-f]{40}"' scripts/large_blob_rewrite.py | sed -E 's/b"([0-9a-f]{40})"/\1/' | sort -u > target_blobs.txt
          echo "Parsed $(wc -l < target_blobs.txt) target blob SHAs from script:" && cat target_blobs.txt
          while read sha; do
            if git cat-file -t "$sha" >/dev/null 2>&1; then echo "$sha PRESENT"; else echo "$sha MISSING"; fi;
          done < target_blobs.txt > target_presence_pre.txt
          echo 'Target presence (pre):'
          cat target_presence_pre.txt

      - name: Install git-filter-repo
        run: |
          python -m pip install --upgrade pip
          python -m pip install git-filter-repo
          python -c "import git_filter_repo, sys; print('git-filter-repo available; version:', getattr(git_filter_repo, '__version__', 'unknown')); print('Python info:', sys.version)"

      - name: Destructive rewrite
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.dry_run != 'true' && github.event.inputs.confirm == 'YES' }}
        run: |
          echo 'Preparing destructive rewrite via git filter-repo CLI'
          # Filter to blobs that are actually present (avoid no-op noise)
          awk '{ if ($2=="PRESENT") print $1 }' target_presence_pre.txt > present_target_blobs.txt
          count=$(wc -l < present_target_blobs.txt | tr -d ' ')
          if [ "$count" -eq 0 ]; then
            echo 'No target blobs currently present; skipping rewrite.'
            echo 'SKIPPED' > rewrite_skipped.txt
            exit 0
          fi
          echo "Rewriting to strip $count present target blobs";
          cat present_target_blobs.txt
          git filter-repo --force --strip-blobs-with-ids present_target_blobs.txt

      - name: Aggressive GC
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.dry_run != 'true' && github.event.inputs.confirm == 'YES' }}
        run: |
          git reflog expire --all --expire=now
          git gc --prune=now --aggressive
          git repack -adf

      - name: Post (size)
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.dry_run != 'true' && github.event.inputs.confirm == 'YES' }}
        run: git count-objects -vH

      - name: Largest blobs (post)
        run: |
          for idx in .git/objects/pack/pack-*.idx; do
            git verify-pack -v "$idx" | awk '/ blob /{print $1, $3}' | sort -k2 -n | tail -20;
          done | tee rewrite_largest_blobs.txt

      - name: Target presence (post)
        run: |
          while read sha; do if git cat-file -t "$sha" >/dev/null 2>&1; then echo "$sha PRESENT"; else echo "$sha MISSING"; fi; done < target_blobs.txt > target_presence_post.txt
          cat target_presence_post.txt

      - name: Diff report
        run: |
          awk '{print $1":"$2}' baseline_largest_blobs.txt | sort > baseline.tmp
            awk '{print $1":"$2}' rewrite_largest_blobs.txt | sort > post.tmp
            comm -23 baseline.tmp post.tmp > removed_blobs.txt || true
            {
              if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
                echo 'DRY RUN: No destructive rewrite executed. "Removed" list below is a set difference between baseline top-50 and post-run top-20 and does NOT indicate actual deletion.';
              else
                echo 'Removed (or shrunk) blobs (may include unreachable yet):';
              fi
              cat removed_blobs.txt;
              echo 'Top 20 after (post enumeration):';
              cat rewrite_largest_blobs.txt;
              echo 'Target blob presence pre:';
              cat target_presence_pre.txt;
              echo 'Target blob presence post:';
              cat target_presence_post.txt;
            } > diff_report.txt
            tail -40 diff_report.txt

      - name: Upload diagnostics
        uses: actions/upload-artifact@v4
        with:
          name: rewrite-diagnostics
          path: |
            baseline_largest_blobs.txt
            rewrite_largest_blobs.txt
            diff_report.txt
            target_presence_pre.txt
            target_presence_post.txt
            pre_rewrite_head.txt
            largest_blob_paths.txt
            present_target_blobs.txt
            rewrite_skipped.txt
            remote_url.txt

      - name: Force push rewritten history
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.dry_run != 'true' && github.event.inputs.confirm == 'YES' && github.ref == 'refs/heads/main' }}
        run: |
          REMOTE_URL="$(cat remote_url.txt 2>/dev/null || true)"
          if [ -z "$REMOTE_URL" ]; then
            REMOTE_URL="$(git config --get remote.origin.url || true)"
          fi
          if [ -z "$REMOTE_URL" ]; then
            echo 'ERROR: Remote URL not found; aborting push for safety.'
            exit 1
          fi
          if ! git remote | grep -q '^origin$'; then
            echo "Re-adding origin remote $REMOTE_URL"
            git remote add origin "$REMOTE_URL"
          fi
          echo "Force pushing rewritten history to origin/main"
          git push --force origin HEAD:main
          echo "Force pushing tags"
          git push --force origin --tags

      - name: Summary
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Workflow dispatch invoked." >> $GITHUB_STEP_SUMMARY
            echo "dry_run=${{ github.event.inputs.dry_run }}" >> $GITHUB_STEP_SUMMARY
            if [ "${{ github.event.inputs.dry_run }}" != "true" ] && [ "${{ github.event.inputs.confirm }}" = "YES" ]; then
              echo "Destructive rewrite executed." >> $GITHUB_STEP_SUMMARY
            else
              echo "Destructive rewrite NOT executed (dry run or missing confirmation)." >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "Push-triggered diagnostics run (no destructive rewrite)." >> $GITHUB_STEP_SUMMARY
          fi
          echo "Target blob presence post:" >> $GITHUB_STEP_SUMMARY
          cat target_presence_post.txt >> $GITHUB_STEP_SUMMARY
